{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import plotClassification, plotRegression, plot_multiple_images, generateRings, scatter_label_points, loadMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698ac02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8076b2a",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b7fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d688a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('dataset/Xtr.csv', header = None, sep=',', usecols = range(3072))\n",
    "X_test = pd.read_csv('dataset/Xte.csv', header = None, sep=',', usecols = range(3072))\n",
    "Y_train = pd.read_csv('dataset/Ytr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec1d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4293ddc6",
   "metadata": {},
   "source": [
    "# PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eff026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "#Plot of the heatmap matrix\n",
    "M =np.cov(X_train)\n",
    "hm = sns.heatmap(M)\n",
    "plt.title('Heatmap of the covariance matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Computation of the singular value decomposition \n",
    "U, s, V = np.linalg.svd(M)\n",
    "\n",
    "X_train = (U * s)[:, :10]\n",
    "plt.scatter(PCs[:, 0], PCs[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec15309",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d068143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x_train, y_train, test_size=0.25, shuffle=False):\n",
    "   \n",
    "    N = x_train.shape[0]\n",
    "    t_size = int(test_size*N)\n",
    "    \n",
    "    if shuffle: \n",
    "        all_index = np.arange(N)\n",
    "        np.random.shuffle(all_index)\n",
    "        x_train, y_train = x_train.iloc[all_index], y_train.iloc[all_index]\n",
    "        \n",
    "    train_x, train_y, test_x, test_y = x_train.iloc[:N-t_size], y_train.iloc[:N-t_size], x_train.iloc[N-t_size:], y_train.iloc[N-t_size:]\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29797b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train, X_val, y_val = train_test_split(X_train, Y_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c87eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val = X_train[-1250:,:], Y_train.values[-1250:,:]\n",
    "X_train, Y_train = X_train[:-1250,:], Y_train.values[:-1250,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd18147",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac4828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a7da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = (X_train - X_train.mean())/X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb073d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = (X_test - X_train.mean())/X_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f356f5",
   "metadata": {},
   "source": [
    "# Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b9c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructImage(data):\n",
    "\n",
    "    rows = data.values\n",
    "    \n",
    "    nb, N = rows.shape\n",
    "    red_channel = rows[:,:N//3]\n",
    "    min_red = red_channel.min(1).reshape(-1,1)\n",
    "    max_red = red_channel.max(1).reshape(-1,1)\n",
    "    red_channel = (red_channel-min_red)/(max_red-min_red)\n",
    "\n",
    "    green_channel = rows[:,N//3:2*N//3]\n",
    "    min_green = green_channel.min(1).reshape(-1,1)\n",
    "    max_green = green_channel.max(1).reshape(-1,1)\n",
    "    green_channel = (green_channel-min_green)/(max_green-min_green)\n",
    "\n",
    "    blue_channel = rows[:,2*N//3:]\n",
    "    min_blue = blue_channel.min(1).reshape(-1,1)\n",
    "    max_blue = blue_channel.max(1).reshape(-1,1)\n",
    "    blue_channel = (blue_channel-min_blue)/(max_blue-min_blue)\n",
    "\n",
    "    newdata = np.hstack((red_channel,green_channel,blue_channel))\n",
    "    newdata = newdata.reshape(nb,3,32,32).transpose(0,2,3,1)\n",
    "    return newdata\n",
    "\n",
    "def plot_image(data, index):\n",
    "\n",
    "    row = data.iloc[index].values\n",
    "    N = row.shape[0]\n",
    "    red_channel = row[:N//3].reshape(-1,1)\n",
    "    min_value = red_channel.min()\n",
    "    max_value = red_channel.max()\n",
    "    red_channel = np.array(1*(red_channel - min_value)/(max_value-min_value))\n",
    "    \n",
    "    green_channel = row[N//3:2*N//3].reshape(-1,1)\n",
    "    min_value = green_channel.min()\n",
    "    max_value = green_channel.max()\n",
    "\n",
    "    \n",
    "    green_channel = np.array(1*(green_channel - min_value)/(max_value-min_value))\n",
    "\n",
    "\n",
    "    blue_channel = row[2*N//3:].reshape(-1,1)\n",
    "    min_value = blue_channel.min()\n",
    "    max_value = blue_channel.max()\n",
    "    blue_channel = np.array(1*(blue_channel - min_value)/(max_value-min_value))\n",
    "    \n",
    "\n",
    "    image = np.hstack((red_channel,green_channel,blue_channel))\n",
    "    image = image.reshape(32,32,3)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(image)\n",
    "    \n",
    "def create_Submissioncsv(y_test):\n",
    "\n",
    "    f = open(\"result/submission.csv\", \"w\")\n",
    "    f.write(\"Id,Prediction\\n\")\n",
    "    for n in range(len(y_test)):\n",
    "        f.write(\"{},{}\\n\".format(int(n+1),y_test[n]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bdef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = reconstructImage(X_train)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(newdata[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaacecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(X_train,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e675bfd1",
   "metadata": {},
   "source": [
    "# Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBF:\n",
    "    def __init__(self, sigma=1.):\n",
    "        self.sigma = sigma  ## the variance of the kernel\n",
    "    def kernel(self,X,Y):\n",
    "        ## Input vectors X and Y of shape Nxd and Mxd\n",
    "        N, d = X.shape \n",
    "        M, _ = Y.shape\n",
    "        X = X.reshape(N,1,d,1)\n",
    "        Y = Y.reshape(1,M,d,1)\n",
    "        G = ((X-Y).transpose((0, 1, 3, 2))@(X-Y)).reshape(N,M)\n",
    "        return np.exp(-G/(2*self.sigma**2))\n",
    "    \n",
    "class Linear:\n",
    "    def __init__(self): \n",
    "        self = self\n",
    "    def kernel(self,X,Y):\n",
    "        ## Input vectors X and Y of shape Nxd and Mxd\n",
    "        return X @ Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVC:\n",
    "    \n",
    "    def __init__(self, C, kernel, epsilon = 1e-3):\n",
    "        self.type = 'non-linear'\n",
    "        self.C = C                               \n",
    "        self.kernel = kernel        \n",
    "        self.alpha = None\n",
    "        self.support = None\n",
    "        self.epsilon = epsilon\n",
    "        self.norm_f = None\n",
    "        self.diag = None\n",
    "        self.label1 = None\n",
    "        self.label2 = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "       #### You might define here any variable needed for the rest of the code\n",
    "        N = len(y)\n",
    "        K = self.kernel(X,X)\n",
    "        y_diag = np.diag(y)\n",
    "        self.label1 = np.unique(y)[0] \n",
    "        self.label2 = np.unique(y)[1]\n",
    "        \n",
    "        # Lagrange dual problem\n",
    "        def loss(alpha):\n",
    "            #'''--------------dual loss ------------------ '''\n",
    "            return - alpha.sum() + 0.5 * alpha.T @ y_diag @ K @ y_diag @ alpha\n",
    "\n",
    "        # Partial derivate of Ld on alpha\n",
    "        def grad_loss(alpha):\n",
    "            # '''----------------partial derivative of the dual loss wrt alpha-----------------'''\n",
    "            return - np.ones(N) + y_diag @ K @ y_diag @ alpha\n",
    "\n",
    "\n",
    "        # Constraints on alpha of the shape :\n",
    "        # -  d - C*alpha  = 0\n",
    "        # -  b - A*alpha >= 0\n",
    "\n",
    "        fun_eq = lambda alpha: (0 - y.T @ alpha).reshape(1,1) # '''----------------function defining the equality constraint------------------'''        \n",
    "        jac_eq = lambda alpha:  - y #'''----------------jacobian wrt alpha of the  equality constraint------------------'''\n",
    "    \n",
    "        fun_ineq = lambda alpha:  self.C*np.vstack((np.ones((N,1)),np.zeros((N,1)))) - (np.vstack((np.eye(N),-np.eye(N)))@alpha).reshape(2*N,1) # '''---------------function defining the ineequality constraint-------------------'''     \n",
    "        jac_ineq = lambda alpha:   - np.vstack((np.eye(N),-np.eye(N))) # '''---------------jacobian wrt alpha of the  inequality constraint-------------------'''\n",
    "            \n",
    "        constraints = ({'type': 'eq',  'fun': fun_eq, 'jac': jac_eq},\n",
    "                       {'type': 'ineq', \n",
    "                        'fun': fun_ineq , \n",
    "                        'jac': jac_ineq})\n",
    "        \n",
    "        optRes = optimize.minimize(fun=lambda alpha: loss(alpha),\n",
    "                                   x0=np.ones(N), \n",
    "                                   method='SLSQP', \n",
    "                                   jac=lambda alpha: grad_loss(alpha), \n",
    "                                   constraints=constraints)\n",
    "\n",
    "        self.alpha = optRes.x \n",
    "        ## Assign the required attributes\n",
    "        \n",
    "        # Support vectors on the margin\n",
    "        supportIndices = np.logical_and(self.alpha>self.epsilon, self.alpha<self.C-self.epsilon)\n",
    "        self.support = X[supportIndices] #'''------------------- A matrix with each row corresponding to a support vector ------------------'''\n",
    "        \n",
    "        self.b = (y - y_diag @ self.alpha @ K)[supportIndices].mean() #''' -----------------offset of the classifier------------------ '''\n",
    "        self.norm_f = np.sqrt(self.alpha.T @ y_diag @ K @ y_diag @ self.alpha) # '''------------------------RKHS norm of the function f ------------------------------'''\n",
    "        \n",
    "        # Support vectors & intermediate variable \n",
    "        # for computing the separating function\n",
    "        self.X_sp = X[np.where(self.alpha>self.epsilon)]\n",
    "        self.diag = np.diag(y[np.where(self.alpha>self.epsilon)])@ self.alpha[np.where(self.alpha>self.epsilon)]\n",
    "\n",
    "    ### Implementation of the separating function $f$\n",
    "    def separating_function(self,x):\n",
    "        # Input : matrix x of shape N data points times d dimension\n",
    "        # Output: vector of size N\n",
    "        return self.diag.T @ self.kernel(self.X_sp,x)\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict y values in {label1, label2} \"\"\"\n",
    "        d = self.separating_function(X)\n",
    "        print(d)\n",
    "        if str(self.b)=='nan': b = 0\n",
    "        return (self.label1 - self.label2) * (d+self.b > 0) + self.label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7730098",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### ONE TO ONE #############\n",
    "\n",
    "class MultClassSVMClassifier(object):\n",
    "    \n",
    "    def __init__(self, C, kernel):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.classifiers = []\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        # Récupération du nombre de classes\n",
    "        k = np.unique(y_train).size\n",
    "        labels = np.unique(y_train)\n",
    "        # Création des k(k-1)/2 classifieurs\n",
    "        for i in range(k):\n",
    "            for j in range(i+1, k):\n",
    "                svm = KernelSVC(C = self.C, kernel = self.kernel)\n",
    "                indexes = np.logical_or(y_train == labels[i],y_train == labels[j])\n",
    "                svm.fit(X_train[indexes], y_train[indexes])\n",
    "                self.classifiers.append(svm)\n",
    "                \n",
    "    def predict(self, X_test):\n",
    "        predicts = []\n",
    "        for classifier in self.classifiers:\n",
    "            predicts.append(classifier.predict(X_test))\n",
    "            \n",
    "        predicts = np.transpose(predicts)\n",
    "        # Vote à majorité \n",
    "        result = [np.bincount(x).argmax() for x in predicts]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8532cf89",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9adb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_val =np.cov(X_test)\n",
    "U, s, V = np.linalg.svd(M_val)\n",
    "X_test = (U * s)[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab49ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf = SVC(C = 10, gamma = 10000)\n",
    "clf.fit(X_train, Y_train[:,1])\n",
    "\n",
    "test = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfa1359",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62cf33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_val, Y_val[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fc035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1/10000\n",
    "C=100.\n",
    "kernel = RBF(sigma).kernel\n",
    "model = MultClassSVMClassifier(C=C, kernel=kernel)\n",
    "\n",
    "model.fit(X_train, Y_train[:,1])\n",
    "#plotClassification(X_train, Ytr, model, label='Training', ax=ax[2])\n",
    "#Y_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b520198",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44823e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.array(Y_test)<9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2745c39a",
   "metadata": {},
   "source": [
    "# Hog feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be5dfc2",
   "metadata": {},
   "source": [
    "# Test avec sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b654494",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_data = np.zeros((X_train.shape[0],144))\n",
    "for i in range (len(newdata)):\n",
    "    #resized_img = resize(newdata[i], (128*4, 64*4))\n",
    "    resized_img = newdata[i]\n",
    "\n",
    "    fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                        cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
    "\n",
    "\n",
    "    \n",
    "    # Rescale histogram for better display \n",
    "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10)) \n",
    "\n",
    "    hog_data[i] = fd\n",
    "    \n",
    "    if i%500 == 0 : \n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8), sharex=True, sharey=True) \n",
    "\n",
    "        ax1.imshow(resized_img, cmap=plt.cm.gray) \n",
    "        ax1.set_title('Input image') \n",
    "\n",
    "        ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray) \n",
    "        ax2.set_title('Histogram of Oriented Gradients')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a106ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_data_test = np.zeros((X_val.shape[0],144))\n",
    "newdata_test = reconstructImage(X_val)\n",
    "\n",
    "for i in range (len(newdata_test)):\n",
    "    #resized_img = resize(newdata_test[i], (128*4, 64*4))\n",
    "    resized_img = newdata_test[i]\n",
    "\n",
    "    fd, hog_image = hog(resized_img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                        cells_per_block=(1, 1), visualize=True, multichannel=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Rescale histogram for better display \n",
    "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10)) \n",
    "\n",
    "    hog_data_test[i] = fd\n",
    "    \n",
    "    if i%500 == 0 : \n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8), sharex=True, sharey=True) \n",
    "\n",
    "        ax1.imshow(resized_img, cmap=plt.cm.gray) \n",
    "        ax1.set_title('Input image') \n",
    "\n",
    "        ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray) \n",
    "        ax2.set_title('Histogram of Oriented Gradients')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64d8c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf = SVC(gamma='auto', C = 10)\n",
    "clf.fit(hog_data, y_train[\"Prediction\"].values)\n",
    "\n",
    "clf.predict(hog_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(hog_data_test,y_val[\"Prediction\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea584b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3a967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
